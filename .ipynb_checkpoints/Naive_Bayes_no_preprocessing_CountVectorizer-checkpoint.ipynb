{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "12500\n",
      "25000\n",
      "12500\n",
      "12500\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from warnings import simplefilter\n",
    "import nltk\n",
    "\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "train_positive_path = '../Sentiment_Analysis/aclImdb/train/pos/'\n",
    "train_negative_path = '../Sentiment_Analysis/aclImdb/train/neg/'\n",
    "test_positive_path = '../Sentiment_Analysis/aclImdb/test/pos/'\n",
    "test_negative_path = '../Sentiment_Analysis/aclImdb/test/neg/'\n",
    "\n",
    "def read_files_in_path(path):\n",
    "    positive_training_data=[]\n",
    "    for filepath in glob.glob(os.path.join(path, '*.txt')):\n",
    "        with open(filepath,encoding='utf8') as f:\n",
    "            content = f.read()\n",
    "            positive_training_data.append(content)\n",
    "    return positive_training_data\n",
    "\n",
    "#Read training data\n",
    "positive_training_data = read_files_in_path(train_positive_path)\n",
    "print(len(positive_training_data))\n",
    "negative_training_data = read_files_in_path(train_negative_path)\n",
    "print(len(negative_training_data))\n",
    "whole_training_data = positive_training_data+negative_training_data\n",
    "print(len(whole_training_data))\n",
    "\n",
    "#Reading Test Data\n",
    "positive_test_data = read_files_in_path(test_positive_path)\n",
    "print(len(positive_test_data))\n",
    "negative_test_data = read_files_in_path(test_negative_path)\n",
    "print(len(negative_test_data))\n",
    "whole_test_data = positive_test_data+negative_test_data\n",
    "print(len(whole_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply feature extraction: countVectorizer which is based on bag of words algorithm\n",
    "vectorizer = CountVectorizer(ngram_range=(1,4))\n",
    "train_vector = vectorizer.fit_transform(whole_training_data)\n",
    "test_vector = vectorizer.transform(whole_test_data)\n",
    "#create labels for the training data and test data first 12500 are positive and the remaining 12500 are negative\n",
    "train_labels = np.asarray([1]*len(positive_training_data) + [0]*len(negative_training_data))\n",
    "test_labels = np.asarray([1]*len(positive_test_data) + [0]*len(negative_test_data))\n",
    "\n",
    "# #printing some visualization of the sizes of the train and test vectors \n",
    "# print(train_labels.shape)\n",
    "# #train_vector has 25000 row corresponding to the 25000 review and 74849 feature extracted\n",
    "# print(train_vector.shape)\n",
    "\n",
    "# #print shapes of test vector and label\n",
    "\n",
    "# print(test_labels.shape)\n",
    "# print(test_vector.shape)\n",
    "\n",
    "# #some visualization for th labels arrays\n",
    "# print(train_labels)\n",
    "# print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  param_alpha  mean_test_score\n",
      "0         0.5          0.84380\n",
      "1         0.8          0.84808\n",
      "2           1          0.84972\n",
      "3           2          0.85428\n",
      "4           3          0.85468\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "\n",
    "clf = GridSearchCV(MultinomialNB(),{'alpha':[0.5,0.8,1.0,2.0,3.0]},cv=5,return_train_score=False)\n",
    "clf.fit(train_vector, train_labels)\n",
    "df=pd.DataFrame(clf.cv_results_)\n",
    "print(df[['param_alpha','mean_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86.   85.   86.58 84.5  85.26]\n",
      "Mean Accuracy: 85.47  (+/- 0.01 deviation) \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha=3)\n",
    "scores = cross_val_score(clf, train_vector, train_labels, cv=5)\n",
    "print(scores*100)\n",
    "print(\"Mean Accuracy: %0.2f  (+/- %0.2f deviation) \" % (scores.mean()*100, scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with no preprocessing & using CountVectorizer classification accuracy:\n",
      " 87.636 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "gnb = MultinomialNB(alpha=3)\n",
    "gnb.fit(train_vector, train_labels)\n",
    "print(\"Naive Bayes with no preprocessing & using CountVectorizer classification accuracy:\\n\",gnb.score(test_vector,test_labels)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
